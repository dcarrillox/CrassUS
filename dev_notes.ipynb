{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9df4e61-e3b1-488c-9400-ab839522a82f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Crassus: Development notes\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "329be7e4-7963-4c27-be74-d4a045ba215a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python imports\n",
    "from Bio import SeqIO\n",
    "import os, glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d73a54-332f-4518-81a9-40adca1a178d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Reference crAss set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17e5002-a385-4fac-a34d-8917e56b7a41",
   "metadata": {
    "tags": []
   },
   "source": [
    "Originally I used all the genomes that we have (~2k), comprising complete and uncomplete genomes. Besides this might be too much redundancy, classification by ANI would be incorrect for uncomplete genomes. Because of this **I decide to use only the ones listed at `contigs_clustering.xlsx`, with the complete and taxonomically classified genomes from the proposal**. Using type species would be too few though. \n",
    "\n",
    "So, I change the whole reference set to include in the the container. 846 complete crAss genomes (excluding crass-env) in `contigs_clustering.xlsx`, but I still add the reference Bas' crass (crass001 is already in the list) and the two outgroups, so it makes 849 at the end. I change the .fasta files under `/genomes` and the proteins in `all_crass_proteins.faa` according to this. ⚠️ **WARNING** ⚠️ Because of the lack/split of TerL gene in 8 genomes, the final number is 841, read below.\n",
    "\n",
    "Regarding the terminases, I extract them with Biopython. I grab all the trimmed, merged terminases from `bas/february_2021/terLterL_sequences_trimmed_merged.faa`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6049b0ca-6aa9-45a9-b480-45cf53cb96e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3300008523_____Ga0115231_1000095', 'OAWB01000083', '3300014553_____Ga0134451_100057', 'ERR589831_NODE_127_length_97341_cov_28.7607', 'OLOZ01000093', 'OLQU01000060', 'ERR589503_NODE_260_length_95985_cov_44.2112', 'ERR589804_NODE_183_length_96082_cov_14.9851']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read \"crassus_genomes.txt\" with the target genomes ids\n",
    "target_genomes = [line.strip() for line in open(\"crassus_genomes.txt\").readlines()]\n",
    "\n",
    "# read the .faa file with all the terminases. Store the ones from the target genomes\n",
    "to_write = list()\n",
    "records = SeqIO.parse(\"container/terL_sequences_trimmed_merged.faa\", \"fasta\")\n",
    "for record in records:\n",
    "    genome = record.id.split(\"|\")[0]\n",
    "    if genome in target_genomes:\n",
    "        to_write.append(record)\n",
    "        target_genomes.remove(genome)\n",
    "        \n",
    "with open(\"container/crass_reference_TerL.faa\", \"w\") as fout:\n",
    "    SeqIO.write(to_write, fout, \"fasta\")\n",
    "                \n",
    "# print genomes without a final TerL protein \n",
    "print(target_genomes)\n",
    "len(target_genomes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdca463-0588-444e-b29e-fc6e4cafd831",
   "metadata": {
    "tags": []
   },
   "source": [
    "Note well the 8 genomes without a TerL gene. **I remove them from the reference set so far**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "34df6a55-005c-417f-9665-b4aedf0bad66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# remove them from the genomes folder\n",
    "for genome in target_genomes:\n",
    "    if os.path.isfile(f\"container/genomes/{genome}.fasta\"):\n",
    "        print(f\"deleting {genome} genome\")\n",
    "        os.remove(f\"container/genomes/{genome}.fasta\")\n",
    "        \n",
    "# remove them from `all_crass_proteins.faa` \n",
    "to_write = list()\n",
    "records = SeqIO.parse(\"container/all_crass_proteins.faa\", \"fasta\")\n",
    "for record in records:\n",
    "    genome = record.id.split(\"|\")[0]\n",
    "    if genome not in target_genomes:\n",
    "        to_write.append(record)\n",
    "\n",
    "with open(\"container/all_crass_proteins.faa\", \"w\") as fout:\n",
    "    SeqIO.write(to_write, fout, \"fasta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f8c24c-d4c3-464d-99ad-80842dd36c19",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "### TerL tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca868b5-550b-4a44-b323-b8b8e34322fa",
   "metadata": {},
   "source": [
    "The reference set are 841 genomes with their proteins and terminases. I don't know how long is gonna take to align all these sequences + the sequences found by the pipeline.\n",
    "\n",
    "`mafft-einsi` took 15 mins with 841 seqs and 93 CPUs.\n",
    "- `(mafft_env) danielc@mutant5:/linuxhome/tmp/danielc/crassus_terl:time mafft-einsi --thread 93 --quiet crass_reference_TerL.faa > crass_reference_TerL.mafft-einsi`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fad29ca-0077-4eeb-82ac-f2abfec5567a",
   "metadata": {},
   "source": [
    "---\n",
    "### Branch and merge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c967d441-145f-48c3-98ab-e7eac39ba6ff",
   "metadata": {},
   "source": [
    "I want to play with this. Let's refactor de pipeline, brach **refactor**. \n",
    "\n",
    "\\# create branch and move to it\\\n",
    "`$ git checkout -b refactor`\n",
    "\n",
    "\\# change the stuff I want to change and commit it\\\n",
    "`$ git add .gitignore dev_notes.ipynb workflow/Snakefile workflow/rules/`\n",
    "`$ git commit -m \"refactor initial rules\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e1a347-3419-4990-8785-8eb29f537b85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cc2d86-19f1-414e-88e8-c625dbec9199",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6abd44-1467-4cfa-aac2-ba350b4dbfd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90f9b8b-4817-4898-bf8f-9166ed973591",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
